[TOC]
### 流计算概述
#### 流数据
`流数据`，即数据以**大量**、**快速**、**时变**的流形式持续到达。<br>
+ 实例：PM2.5检测、电子商务网站用户点击流

流数据具有如下特征：
1. 数据快速持续到达，潜在大小也许是无穷无尽的
2. 数据来源众多，格式复杂
3. 数据量大，但是不关注存储，一旦经过处理，要么被丢弃，要么被归档存储
4. 注重数据的整体价值，不过分关注个别数据
5. 数据顺序颠倒，或者不完整，**系统无法控制将要处理的新到达的数据元素的顺序**

#### 批量计算和实时计算
<img src="images/spark/sparkStreaming_数据的两种处理模型.png" width="250" height="200" align="center">
批量计算：充裕时间处理静态数据，如Hadoop<br>
流计算：<br>
* 流数据不适合采用批量计算，因为流数据不适合用传统的关系模型建模。<br>
* 流数据必须采用`实时计算`，响应时间为`秒级`
* 数据量少时，不是问题，但是，在大数据时代，数据格式复杂、来源众多、数据量巨大，对实时计算提出了很大的挑战。




#### Spark Streaming
#### DStream操作概述
#### 基本输入源
#### 高级数据源
#### 转换操作
#### 输出操作

### 参考引用
+ [子雨大数据之Spark入门教程（Scala版）](https://dblab.xmu.edu.cn/blog/924/)












